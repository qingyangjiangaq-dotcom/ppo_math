"""ç¾è§‚çš„è®­ç»ƒç›‘æ§å’Œæ‰“å°å·¥å…·"""
from datetime import datetime
from typing import Dict, List, Any

class Colors:
    """ç»ˆç«¯é¢œè‰²ä»£ç """
    HEADER = '\033[95m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'
    END = '\033[0m'


def print_header(text: str):
    """æ‰“å°å¤§æ ‡é¢˜"""
    width = 70
    print(f"\n{Colors.HEADER}{'='*width}{Colors.END}")
    print(f"{Colors.HEADER}{Colors.BOLD}{text.center(width)}{Colors.END}")
    print(f"{Colors.HEADER}{'='*width}{Colors.END}\n")


def print_subheader(text: str):
    """æ‰“å°å°æ ‡é¢˜"""
    print(f"\n{Colors.CYAN}{Colors.BOLD}â–¶ {text}{Colors.END}")
    print(f"{Colors.CYAN}{'â”€'*50}{Colors.END}")


def print_metric(name: str, value: float, unit: str = "", color: str = None, width: int = 20):
    """æ‰“å°å•ä¸ªæŒ‡æ ‡"""
    if color is None:
        if value > 0.7:
            color = Colors.GREEN
        elif value > 0.3:
            color = Colors.YELLOW
        else:
            color = Colors.RED
    
    name_str = f"{name}:".ljust(width)
    value_str = f"{value:.4f}{unit}"
    print(f"  {Colors.BOLD}{name_str}{Colors.END} {color}{value_str}{Colors.END}")


def print_metrics_table(metrics: Dict[str, float], title: str = "æŒ‡æ ‡"):
    """æ‰“å°æŒ‡æ ‡è¡¨æ ¼"""
    print_subheader(title)
    
    # åˆ†ç±»æ˜¾ç¤º
    categories = {
        "å¥–åŠ±ç›¸å…³": ["mean_reward", "std_reward", "parse_rate", "format_rate", "accuracy"],
        "è®­ç»ƒç›¸å…³": ["policy_loss", "value_loss", "total_loss", "approx_kl", "entropy", "clip_frac"],
        "æ•ˆç‡ç›¸å…³": ["step_time_sec", "gen_tokens_per_sec", "samples_per_sec", "gpu_mem_gb"]
    }
    
    for category, keys in categories.items():
        has_any = any(k in metrics for k in keys)
        if not has_any:
            continue
            
        print(f"\n{Colors.YELLOW}{category}:{Colors.END}")
        for key in keys:
            if key in metrics and metrics[key] is not None:
                value = metrics[key]
                # æ ¼å¼åŒ–æ˜¾ç¤º
                if "rate" in key or "accuracy" in key or "frac" in key:
                    print_metric(key.replace("_", " ").title(), value, "", width=18)
                elif "loss" in key or "kl" in key or "entropy" in key:
                    print_metric(key.replace("_", " ").title(), value, "", width=18)
                elif "time" in key:
                    print_metric(key.replace("_", " ").title(), value, "s", width=18)
                elif "mem" in key:
                    print_metric(key.replace("_", " ").title(), value, "GB", width=18)
                elif "per_sec" in key:
                    print_metric(key.replace("_", " ").title(), value, "/s", width=18)
                else:
                    print_metric(key.replace("_", " ").title(), value, "", width=18)


def print_response_analysis(response: str, pred: str, gold: str, reward: float, 
                           question: str = "", sample_idx: int = 0):
    """ç¾è§‚åœ°æ‰“å°æ¨¡å‹å›å¤å’Œåˆ†æ"""
    print_subheader(f"æ ·æœ¬ #{sample_idx + 1}")
    
    if question:
        print(f"{Colors.YELLOW}é—®é¢˜:{Colors.END} {question[:80]}..." if len(question) > 80 else f"{Colors.YELLOW}é—®é¢˜:{Colors.END} {question}")
    
    # åˆ¤æ–­çŠ¶æ€
    is_correct = pred == gold
    is_parsed = pred is not None and pred != ""
    
    # æ‰“å°é¢„æµ‹ç»“æœ
    status_color = Colors.GREEN if is_correct else (Colors.YELLOW if is_parsed else Colors.RED)
    status_text = "âœ“ æ­£ç¡®" if is_correct else ("âš  è§£ææˆåŠŸä½†é”™è¯¯" if is_parsed else "âœ— è§£æå¤±è´¥")
    
    print(f"\n{Colors.BOLD}é¢„æµ‹çŠ¶æ€:{Colors.END} {status_color}{status_text}{Colors.END}")
    print(f"{Colors.BLUE}æ¨¡å‹é¢„æµ‹:{Colors.END} {pred if pred else 'N/A'}")
    print(f"{Colors.BLUE}æ ‡å‡†ç­”æ¡ˆ:{Colors.END} {gold if gold else 'N/A'}")
    
    # æ‰“å°å¥–åŠ±
    reward_color = Colors.GREEN if reward > 0.5 else (Colors.YELLOW if reward > -0.3 else Colors.RED)
    print(f"{Colors.BOLD}è·å¾—å¥–åŠ±:{Colors.END} {reward_color}{reward:+.2f}{Colors.END}")
    
    # æ‰“å°å›å¤å†…å®¹ï¼ˆæ ¼å¼åŒ–ï¼‰
    print(f"\n{Colors.CYAN}æ¨¡å‹å›å¤:{Colors.END}")
    print(f"{Colors.CYAN}â”Œ{'â”€'*68}â”{Colors.END}")
    
    # æ™ºèƒ½æ ¼å¼åŒ–å›å¤
    lines = response.strip().split('\n')
    for i, line in enumerate(lines[:15]):  # æœ€å¤šæ˜¾ç¤º15è¡Œ
        if len(line) > 68:
            line = line[:65] + "..."
        print(f"{Colors.CYAN}â”‚{Colors.END} {line.ljust(66)} {Colors.CYAN}â”‚{Colors.END}")
    
    if len(lines) > 15:
        print(f"{Colors.CYAN}â”‚{Colors.END} ... ({len(lines)-15} è¡Œçœç•¥)".ljust(67) + f"{Colors.CYAN}â”‚{Colors.END}")
    
    print(f"{Colors.CYAN}â””{'â”€'*68}â”˜{Colors.END}")


def analyze_training_status(metrics: Dict[str, float], step: int) -> str:
    """åˆ†æè®­ç»ƒçŠ¶æ€å¹¶è¿”å›ç®€çŸ­è¯Šæ–­"""
    analysis = []
    
    # å¥–åŠ±åˆ†æ
    mean_reward = metrics.get("mean_reward", 0)
    parse_rate = metrics.get("parse_rate", 0)
    format_rate = metrics.get("format_rate", 0)
    
    if mean_reward > 0.5:
        analysis.append(f"{Colors.GREEN}å¥–åŠ±è‰¯å¥½{Colors.END} (avg: {mean_reward:.2f})")
    elif mean_reward > 0:
        analysis.append(f"{Colors.YELLOW}å¥–åŠ±ä¸€èˆ¬{Colors.END} (avg: {mean_reward:.2f})")
    else:
        analysis.append(f"{Colors.RED}å¥–åŠ±åä½{Colors.END} (avg: {mean_reward:.2f}) âš ï¸ å¯èƒ½éœ€æ£€æŸ¥å¥–åŠ±å‡½æ•°")
    
    # è§£æç‡åˆ†æ
    if parse_rate > 0.8:
        analysis.append(f"{Colors.GREEN}è§£æç‡é«˜{Colors.END} ({parse_rate:.1%})")
    elif parse_rate > 0.5:
        analysis.append(f"{Colors.YELLOW}è§£æç‡ä¸­ç­‰{Colors.END} ({parse_rate:.1%})")
    else:
        analysis.append(f"{Colors.RED}è§£æç‡ä½{Colors.END} ({parse_rate:.1%}) âš ï¸ æ¨¡å‹æœªå­¦ä¼šæ ¼å¼")
    
    # æ ¼å¼ç‡åˆ†æ
    if format_rate > 0.8:
        analysis.append(f"{Colors.GREEN}æ ¼å¼æ­£ç¡®ç‡é«˜{Colors.END} ({format_rate:.1%})")
    elif format_rate > 0.5:
        analysis.append(f"{Colors.YELLOW}æ ¼å¼ç‡ä¸­ç­‰{Colors.END} ({format_rate:.1%})")
    else:
        analysis.append(f"{Colors.RED}æ ¼å¼ç‡ä½{Colors.END} ({format_rate:.1%})")
    
    # KLæ•£åº¦åˆ†æ
    kl = metrics.get("approx_kl")
    if kl is not None:
        if kl > 0.5:
            analysis.append(f"{Colors.RED}KLè¿‡é«˜{Colors.END} ({kl:.3f}) âš ï¸ ç­–ç•¥åç¦»è¿‡å¤§")
        elif kl > 0.1:
            analysis.append(f"{Colors.GREEN}KLæ­£å¸¸{Colors.END} ({kl:.3f})")
        else:
            analysis.append(f"{Colors.YELLOW}KLè¾ƒä½{Colors.END} ({kl:.3f})")
    
    # æŸå¤±åˆ†æ
    policy_loss = metrics.get("policy_loss")
    if policy_loss is not None and abs(policy_loss) > 1.0:
        analysis.append(f"{Colors.RED}ç­–ç•¥æŸå¤±è¿‡å¤§{Colors.END} ({policy_loss:.3f})")
    
    return " | ".join(analysis)


def print_training_step(step: int, metrics: Dict[str, float], 
                       responses: List[str], preds: List[str], golds: List[str],
                       rewards: List[float], questions: List[str] = None):
    """æ‰“å°å®Œæ•´çš„è®­ç»ƒæ­¥éª¤ä¿¡æ¯"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    
    # å¤§æ ‡é¢˜
    print_header(f"ğŸš€ è®­ç»ƒæ­¥éª¤ {step} | {timestamp}")
    
    # åˆ†æçŠ¶æ€
    print_subheader("ğŸ“Š çŠ¶æ€åˆ†æ")
    analysis = analyze_training_status(metrics, step)
    print(f"  {analysis}\n")
    
    # æ‰“å°æŒ‡æ ‡è¡¨æ ¼
    print_metrics_table(metrics, "ğŸ“ˆ è¯¦ç»†æŒ‡æ ‡")
    
    # æ‰“å°æ ·æœ¬å›å¤
    if responses:
        print_subheader("ğŸ’¬ æ¨¡å‹å›å¤æ ·ä¾‹")
        for i, (resp, pred, gold, reward) in enumerate(zip(responses[:3], preds[:3], golds[:3], rewards[:3])):
            q = questions[i] if questions and i < len(questions) else ""
            print_response_analysis(resp, pred, gold, reward, q, i)
    
    print(f"\n{Colors.HEADER}{'='*70}{Colors.END}\n")


if __name__ == "__main__":
    # æµ‹è¯•æ‰“å°æ•ˆæœ
    test_metrics = {
        "mean_reward": 0.85,
        "std_reward": 0.15,
        "parse_rate": 0.92,
        "format_rate": 0.88,
        "approx_kl": 0.15,
        "entropy": 0.42,
        "clip_frac": 0.12,
        "policy_loss": 0.03,
        "value_loss": 0.08,
        "total_loss": 0.11,
        "step_time_sec": 2.34,
        "gen_tokens_per_sec": 125.5,
        "gpu_mem_gb": 6.8
    }
    
    test_responses = [
        "é¦–å…ˆï¼Œå°æ˜æœ‰3ä¸ªè‹¹æœã€‚\nç„¶åï¼Œä»–åƒæ‰1ä¸ªã€‚\næ‰€ä»¥å‰©ä¸‹ 3-1=2 ä¸ªã€‚\n#### 2",
        "è¿™æ˜¯ä¸€ä¸ªå¤æ‚çš„é—®é¢˜ã€‚\nè®©æˆ‘æ€è€ƒä¸€ä¸‹...\nç­”æ¡ˆæ˜¯ 42ã€‚\n#### 42"
    ]
    
    print_training_step(
        step=10,
        metrics=test_metrics,
        responses=test_responses,
        preds=["2", "42"],
        golds=["2", "43"],
        rewards=[1.5, -0.5],
        questions=["å°æ˜æœ‰3ä¸ªè‹¹æœï¼Œåƒæ‰1ä¸ªï¼Œå‰©å‡ ä¸ªï¼Ÿ", "5+3*7=?"]
    )
