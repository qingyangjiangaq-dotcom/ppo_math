[
  "objective/entropy",
  "objective/kl",
  "objective/kl_coef",
  "objective/kl_dist",
  "objective/logprobs",
  "objective/ref_logprobs",
  "ppo/learning_rate",
  "ppo/loss/policy",
  "ppo/loss/total",
  "ppo/loss/value",
  "ppo/mean_non_score_reward",
  "ppo/mean_scores",
  "ppo/policy/advantages",
  "ppo/policy/advantages_mean",
  "ppo/policy/approxkl",
  "ppo/policy/clipfrac",
  "ppo/policy/entropy",
  "ppo/policy/policykl",
  "ppo/policy/ratio",
  "ppo/returns/mean",
  "ppo/returns/var",
  "ppo/std_scores",
  "ppo/val/clipfrac",
  "ppo/val/error",
  "ppo/val/mean",
  "ppo/val/var",
  "ppo/val/var_explained",
  "ppo/val/vpred",
  "time/ppo/calc_stats",
  "time/ppo/compute_advantages",
  "time/ppo/compute_rewards",
  "time/ppo/forward_pass",
  "time/ppo/optimize_step",
  "time/ppo/total",
  "tokens/queries_dist",
  "tokens/queries_len_mean",
  "tokens/queries_len_std",
  "tokens/responses_dist",
  "tokens/responses_len_mean",
  "tokens/responses_len_std"
]